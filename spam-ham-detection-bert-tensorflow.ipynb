{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d77a84-03e6-444c-ae8e-c6ec3fb29c61",
   "metadata": {},
   "source": [
    "# **Spam Ham Detection Using BERT and Tensorflow**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f758b9b-dab7-4279-929a-489595f95945",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0124063-db8f-4910-a79b-bc86ed6b348b",
   "metadata": {},
   "source": [
    "##### <u>**Project Summary**</u>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ddf71ae5-c10b-4ad5-9651-b5ccd899d8bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37e9cdff-2369-4ff8-8ef2-2028018b55e8",
   "metadata": {},
   "source": [
    "##### <u>**GitHub Link**</u>\n",
    "[Click Here](https://github.com/ajitmane36/spam-ham-detection-bert-tensorflow.git)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6cc20-607f-4599-8f22-b0e6ee0c306d",
   "metadata": {},
   "source": [
    "##### <u>**Problem Statement**</u>\n",
    "\n",
    "- The data is related to the classification of emails into spam or ham (non-spam). The goal of this project is to develop a model using BERT and TensorFlow to predict whether an email is spam or not based on its content. By fine-tuning a pre-trained BERT model, the objective is to enhance the accuracy and efficiency of email classification, ensuring that legitimate emails are delivered to the inbox while spam is effectively filtered out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d4c68e-068a-42d1-9392-2532e4ffb3be",
   "metadata": {},
   "source": [
    "##### <u>**Data Description**</u>\n",
    "\n",
    "- **Message**: Description of the email content (text).\n",
    "- **Category**: Indicates whether the email is spam (1) or not (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f65d089-866b-4902-815b-8ba143b1d048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.13.0\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-text==2.13. (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow-text==2.13.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.13.0 tensorflow-text==2.13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2df1e415-9ddc-476b-be40-85dac8ffa007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official==2.13.*\n",
      "  Using cached tf_models_official-2.13.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting Cython (from tf-models-official==2.13.*)\n",
      "  Using cached Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (10.3.0)\n",
      "Collecting gin-config (from tf-models-official==2.13.*)\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-api-python-client>=1.6.7 (from tf-models-official==2.13.*)\n",
      "  Using cached google_api_python_client-2.136.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting immutabledict (from tf-models-official==2.13.*)\n",
      "  Using cached immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting kaggle>=1.3.9 (from tf-models-official==2.13.*)\n",
      "  Using cached kaggle-1.6.14.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (3.8.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (1.24.4)\n",
      "Collecting oauth2client (from tf-models-official==2.13.*)\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting opencv-python-headless (from tf-models-official==2.13.*)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (1.5.3)\n",
      "Requirement already satisfied: psutil>=5.4.3 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (9.0.0)\n",
      "Collecting pycocotools (from tf-models-official==2.13.*)\n",
      "  Using cached pycocotools-2.0.8-cp311-cp311-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (6.0.1)\n",
      "Collecting sacrebleu (from tf-models-official==2.13.*)\n",
      "  Using cached sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (1.10.1)\n",
      "Collecting sentencepiece (from tf-models-official==2.13.*)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting seqeval (from tf-models-official==2.13.*)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (1.16.0)\n",
      "Collecting tensorflow-datasets (from tf-models-official==2.13.*)\n",
      "  Using cached tensorflow_datasets-4.9.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in c:\\users\\ajitm\\anaconda3\\lib\\site-packages (from tf-models-official==2.13.*) (0.16.1)\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.13.*)\n",
      "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
      "INFO: pip is looking at multiple versions of tf-models-official to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tf-models-official==2.13.*\n",
      "  Using cached tf_models_official-2.13.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official==2.13.*)\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tf-models-official==2.13.*\n",
      "  Using cached tf_models_official-2.13.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyyaml<6.0,>=5.1 (from tf-models-official==2.13.*)\n",
      "  Using cached PyYAML-5.4.1.tar.gz (175 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [54 lines of output]\n",
      "      running egg_info\n",
      "      writing lib3\\PyYAML.egg-info\\PKG-INFO\n",
      "      writing dependency_links to lib3\\PyYAML.egg-info\\dependency_links.txt\n",
      "      writing top-level names to lib3\\PyYAML.egg-info\\top_level.txt\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\ajitm\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\ajitm\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ajitm\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 327, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 297, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 313, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 271, in <module>\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 184, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 200, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 970, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 974, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 989, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 321, in run\n",
      "          self.find_sources()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 329, in find_sources\n",
      "          mm.run()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 550, in run\n",
      "          self.add_defaults()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 588, in add_defaults\n",
      "          sdist.add_defaults(self)\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\command\\sdist.py\", line 102, in add_defaults\n",
      "          super().add_defaults()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 250, in add_defaults\n",
      "          self._add_defaults_ext()\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 335, in _add_defaults_ext\n",
      "          self.filelist.extend(build_ext.get_source_files())\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 201, in get_source_files\n",
      "        File \"C:\\Users\\ajitm\\AppData\\Local\\Temp\\pip-build-env-v0e713bk\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 107, in __getattr__\n",
      "          raise AttributeError(attr)\n",
      "      AttributeError: cython_sources\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "#!pip install -U \"tensorflow-text==2.13.*\"\n",
    "!pip install \"tf-models-official==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6227fde2-767a-4826-bce5-5770db1cac5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000262EA4D1AD0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-text/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000262E724C1D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-text/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000262EA6C8F10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-text/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000262EA6CCED0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-text/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000262EA6CDE50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tensorflow-text/\n",
      "ERROR: Could not find a version that satisfies the requirement tensorflow-text==2.13.* (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow-text==2.13.*\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000130BDA1E710>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tf-models-official/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000130BDA54C90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tf-models-official/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000130C0E60990>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tf-models-official/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000130C0E708D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tf-models-official/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x00000130C0E77E10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/tf-models-official/\n",
      "ERROR: Could not find a version that satisfies the requirement tf-models-official==2.13.* (from versions: none)\n",
      "ERROR: No matching distribution found for tf-models-official==2.13.*\n"
     ]
    }
   ],
   "source": [
    "# A dependency of the preprocessing for BERT inputs\n",
    "!pip install -U \"tensorflow-text==2.13.*\"\n",
    "!pip install \"tf-models-official==2.13.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c76b328-bd1c-4f62-8797-cce75b73cd44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:52\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Real\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:88\u001b[0m\n\u001b[0;32m     79\u001b[0m MAX_IMAGE_PIXELS: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     91\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     93\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _imaging: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing tensorflow libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc56a225-5626-46a6-8291-da92f03ce470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Loading\n",
    "df=pd.read_csv(r\"C:\\Users\\ajitm\\Downloads\\DS Projects\\Deep Larning Projects\\1. Text Classification Using BERT & Tensorflow\\spam_emails_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd050d32-6a75-466c-b1eb-c0acd0423039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fist five observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3326d4cf-66bd-4eb4-a9e1-477595844a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last five observations\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904d6f01-66ed-4db9-ad02-385d7e78adf9",
   "metadata": {},
   "source": [
    "##### <u>**Data Inispection**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f26671-51b5-48e1-b1ab-46b5f6f5bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of dataset\n",
    "df.shape\n",
    "print(f'Dataset has {df.shape[0]} observations and {df.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f9ad0c-2dd5-4876-bf9d-312fad23023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset columns\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fff068-7dfe-4986-815e-ce152790c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information of dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b008e-65d7-42cf-b2d9-09e4f25ac81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic description of dataset\n",
    "df.groupby('Category').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c09b38f-796e-4b6e-8941-f69603917706",
   "metadata": {},
   "source": [
    "- Dataset having 4825 Ham observations and 747 spam observations.\n",
    "- Class imbalance seen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b06c1-5cbc-4258-b463-a25978b50a46",
   "metadata": {},
   "source": [
    "##### <u>**Data Wrangling**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e46691-ad67-4dbe-857c-497f7719cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cehcking  duplicates value in each feature\n",
    "duplicates_df=pd.DataFrame({'columns':df.columns, 'number_of_duplicates': df.duplicated().sum()}).sort_values(by='number_of_duplicates', ascending=False)\n",
    "print(duplicates_df)\n",
    "print(f'Dataset having {df.duplicated().sum()} duplicates values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00833df7-b353-47ce-b761-e2a7c3695c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e265195-9c0e-4f04-8ae5-ab58c159c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "null_df=pd.DataFrame({'columns': df.columns, 'num_of_nulls': df.isna().sum()})\n",
    "print(null_df )\n",
    "print(f'Dataset have {df.isna().sum()} null values.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807666e8-c4d6-423a-820a-981d07bcf809",
   "metadata": {},
   "source": [
    "##### <u>**Exploratory Data Analysis**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc7acd-0dd1-4c57-8c4a-641c054e8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min and Max length of email\n",
    "print(\"Smallest email\")\n",
    "print('__'*50)\n",
    "print(df.Message.min())\n",
    "print(f'Length: {len(df.Message.min())}')\n",
    "print('=='*50)\n",
    "print(\"Largest email\")\n",
    "print('__'*50)\n",
    "print(df.Message.max())\n",
    "print(f'Length: {len(df.Message.max())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53025be-70d9-4f49-a942-fa5258aa87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to Notate the percent count of each value on the bars\n",
    "def annot_percent(axes):\n",
    "    '''Takes axes as input and labels the percent count of each bar in a countplot'''\n",
    "    for p in plot.patches:\n",
    "        total = sum(p.get_height() for p in plot.patches)/100\n",
    "        percent = round((p.get_height()/total),2)\n",
    "        x = p.get_x() + p.get_width()/2\n",
    "        y = p.get_height()\n",
    "        plot.annotate(f'{percent}%', (x, y), ha='center', va='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0e9bd-a7da-404e-8e3b-dd0ab31032a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for diffrent categories of email \n",
    "plt.figure(figsize=(7,5))\n",
    "plot=plt.subplot(111)\n",
    "ax=sns.countplot(x=df.Category, hue=df.Category)\n",
    "ax.set_title('Countplot for different emails categories')\n",
    "ax.legend('Category', title='Emails Categories')\n",
    "annot_percent(plot)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7c082-7465-4912-be62-8e53c612c4fb",
   "metadata": {},
   "source": [
    "- Dataset have 12.43% of spam and 87.57% ham observations.\n",
    "- Class imbalnce seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67cf7c-e586-4cb5-9002-fb13b4132297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of each emial\n",
    "df['length']=df['Message'].apply(lambda x:len(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5d4e60-161d-4e54-a478-8eb2571170f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram for length of emails\n",
    "plt.figure(figsize=(7,5))\n",
    "ax=sns.histplot(x=df.length, hue=df.Category)\n",
    "ax.set_title('Histogram for length of emails')\n",
    "ax.axvline(df.length.mean(), color='r', linestyle='--')\n",
    "ax.text(df.length.mean(), ax.get_ylim()[1]*0.9, f'Average Emails Length: {df.length.mean():.2f}', \n",
    "        color='red', ha='left', va='top', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb74227-cd2a-4c38-b772-759a960ffd9c",
   "metadata": {},
   "source": [
    "- The average email length seen is 79.\n",
    "- The majority of emails are shorter than 200 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8793771-2065-4976-b344-7a32cebb6849",
   "metadata": {},
   "source": [
    "##### <u>**Feature Engineering & Data Pre-processing**</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a24bbb-2e03-493d-95c7-b5b7f0829c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset look\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2be276d-a911-4be6-ad8e-a022d72cbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary 'length' feature\n",
    "df.drop(columns='length', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b98eb-29f3-4d51-b2b6-866ec8a064f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check category in 'Category' feature\n",
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08899cef-6143-4b06-8b7f-23ce32864c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical encoding for 'Category' feature\n",
    "df['spam']=df['Category'].apply(lambda x: 1 if x=='spam' else 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d5d10-e680-4375-8abb-c42be69fbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating dependant and independant varibale\n",
    "\n",
    "# Independant feature\n",
    "X=df['Message'].copy()\n",
    "# Dependant feature\n",
    "y=df['spam'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e102c-8ad3-4b7a-86f5-4c4dfe864aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa5f69-62f0-428e-801c-37020e679179",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Shape of splits\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b3f22-bdd4-42f9-8479-3de2288e7e02",
   "metadata": {},
   "source": [
    "##### <u>**Textual Data Transformation**<u/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74486619-96bb-4b0a-a5e7-68cf3a6c6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade tensorflow tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ee1b0-1e87-4b3b-babd-65fc58fbd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download BERT preprocessing and encoder model from tensorflow hub\n",
    "preprocessor = hub.KerasLayer('https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-preprocess/3')\n",
    "encoder = hub.KerasLayer('https://kaggle.com/models/tensorflow/bert/TensorFlow2/en-uncased-l-12-h-768-a-12/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2036d2-e002-4ae7-80c4-1897a8850f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b2b25-27b2-4551-9e08-e92360cb8355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
